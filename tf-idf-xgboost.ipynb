{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1382412,"sourceType":"datasetVersion","datasetId":806606},{"sourceId":7438246,"sourceType":"datasetVersion","datasetId":4329160}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection, naive_bayes, svm\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\ntrain_url = '/kaggle/input/bangla-dataset/train_corr.csv'\ntest_url = '/kaggle/input/bangla-dataset/test_corr.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:18:22.717488Z","iopub.execute_input":"2024-01-20T02:18:22.717914Z","iopub.status.idle":"2024-01-20T02:18:23.148587Z","shell.execute_reply.started":"2024-01-20T02:18:22.717876Z","shell.execute_reply":"2024-01-20T02:18:23.147100Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:18:25.715017Z","iopub.execute_input":"2024-01-20T02:18:25.715578Z","iopub.status.idle":"2024-01-20T02:18:25.723427Z","shell.execute_reply.started":"2024-01-20T02:18:25.715533Z","shell.execute_reply":"2024-01-20T02:18:25.721774Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:18:27.280796Z","iopub.execute_input":"2024-01-20T02:18:27.281219Z","iopub.status.idle":"2024-01-20T02:18:27.469933Z","shell.execute_reply.started":"2024-01-20T02:18:27.281186Z","shell.execute_reply":"2024-01-20T02:18:27.468803Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"Encoder = LabelEncoder()\nTrain_Y = Encoder.fit_transform(df_train.Error)\nTest_Y = Encoder.fit_transform(df_test.Error)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:18:29.409202Z","iopub.execute_input":"2024-01-20T02:18:29.409641Z","iopub.status.idle":"2024-01-20T02:18:29.417958Z","shell.execute_reply.started":"2024-01-20T02:18:29.409606Z","shell.execute_reply":"2024-01-20T02:18:29.416602Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:18:52.803591Z","iopub.execute_input":"2024-01-20T02:18:52.804130Z","iopub.status.idle":"2024-01-20T02:18:53.739705Z","shell.execute_reply.started":"2024-01-20T02:18:52.804085Z","shell.execute_reply":"2024-01-20T02:18:53.738545Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=100,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:19:00.726178Z","iopub.execute_input":"2024-01-20T02:19:00.727179Z","iopub.status.idle":"2024-01-20T02:19:00.733016Z","shell.execute_reply.started":"2024-01-20T02:19:00.727138Z","shell.execute_reply":"2024-01-20T02:19:00.731713Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model.fit(Train_X_Tfidf, Train_Y)","metadata":{"tags":[],"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = model.predict(Test_X_Tfidf)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T02:19:13.415474Z","iopub.execute_input":"2024-01-20T02:19:13.415898Z","iopub.status.idle":"2024-01-20T02:19:13.434552Z","shell.execute_reply.started":"2024-01-20T02:19:13.415865Z","shell.execute_reply":"2024-01-20T02:19:13.433386Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T01:31:59.344277Z","iopub.execute_input":"2024-01-20T01:31:59.345308Z","iopub.status.idle":"2024-01-20T01:31:59.371404Z","shell.execute_reply.started":"2024-01-20T01:31:59.345267Z","shell.execute_reply":"2024-01-20T01:31:59.370020Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5222    0.0738    0.1294      1910\n           1     0.6277    0.9585    0.7586      3112\n\n    accuracy                         0.6221      5022\n   macro avg     0.5750    0.5162    0.4440      5022\nweighted avg     0.5876    0.6221    0.5193      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-20T01:35:34.257702Z","iopub.execute_input":"2024-01-20T01:35:34.258152Z","iopub.status.idle":"2024-01-20T01:35:35.162076Z","shell.execute_reply.started":"2024-01-20T01:35:34.258119Z","shell.execute_reply":"2024-01-20T01:35:35.160475Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=100,  # Number of boosting rounds (trees)\n    learning_rate=0.01,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:19:19.688534Z","iopub.execute_input":"2024-01-20T02:19:19.688931Z","iopub.status.idle":"2024-01-20T02:19:21.093766Z","shell.execute_reply.started":"2024-01-20T02:19:19.688901Z","shell.execute_reply":"2024-01-20T02:19:21.092890Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000      1910\n           1     0.6197    1.0000    0.7652      3112\n\n    accuracy                         0.6197      5022\n   macro avg     0.3098    0.5000    0.3826      5022\nweighted avg     0.3840    0.6197    0.4742      5022\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"df_all  = pd.concat([df_train, df_test], ignore_index=True)\nTfidf_vect = TfidfVectorizer(max_features=10000)\nTfidf_vect.fit(df_all['Comment'])\nTrain_X_Tfidf = Tfidf_vect.transform(df_train['Comment'])\nTest_X_Tfidf = Tfidf_vect.transform(df_test['Comment'])","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:19:39.272834Z","iopub.execute_input":"2024-01-20T02:19:39.273273Z","iopub.status.idle":"2024-01-20T02:19:40.169164Z","shell.execute_reply.started":"2024-01-20T02:19:39.273237Z","shell.execute_reply":"2024-01-20T02:19:40.168069Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=100,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=3,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:19:42.752748Z","iopub.execute_input":"2024-01-20T02:19:42.753200Z","iopub.status.idle":"2024-01-20T02:19:44.229387Z","shell.execute_reply.started":"2024-01-20T02:19:42.753164Z","shell.execute_reply":"2024-01-20T02:19:44.228514Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5222    0.0738    0.1294      1910\n           1     0.6277    0.9585    0.7586      3112\n\n    accuracy                         0.6221      5022\n   macro avg     0.5750    0.5162    0.4440      5022\nweighted avg     0.5876    0.6221    0.5193      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=200,  # Number of boosting rounds (trees)\n    learning_rate=0.05,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.9,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.9,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred,digits = 4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:19:52.409011Z","iopub.execute_input":"2024-01-20T02:19:52.409444Z","iopub.status.idle":"2024-01-20T02:19:57.988875Z","shell.execute_reply.started":"2024-01-20T02:19:52.409410Z","shell.execute_reply":"2024-01-20T02:19:57.987936Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5408    0.0832    0.1443      1910\n           1     0.6297    0.9566    0.7594      3112\n\n    accuracy                         0.6245      5022\n   macro avg     0.5852    0.5199    0.4519      5022\nweighted avg     0.5959    0.6245    0.5255      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,      # Increased boosting rounds\n    learning_rate=0.05,    # Lower learning rate\n    max_depth=5,           # Increased maximum depth\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,         # L1 regularization term\n    reg_lambda=0.1,        # L2 regularization term\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:20:04.524501Z","iopub.execute_input":"2024-01-20T02:20:04.525394Z","iopub.status.idle":"2024-01-20T02:20:13.217526Z","shell.execute_reply.started":"2024-01-20T02:20:04.525359Z","shell.execute_reply":"2024-01-20T02:20:13.215986Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5458    0.1403    0.2232      1910\n           1     0.6376    0.9283    0.7560      3112\n\n    accuracy                         0.6286      5022\n   macro avg     0.5917    0.5343    0.4896      5022\nweighted avg     0.6027    0.6286    0.5534      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,      # Increased boosting rounds\n    learning_rate=0.01,    # Lower learning rate\n    max_depth=4,           # Increased maximum depth\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,         # L1 regularization term\n    reg_lambda=0.1,        # L2 regularization term\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:02:53.007955Z","iopub.execute_input":"2024-01-20T02:02:53.008365Z","iopub.status.idle":"2024-01-20T02:02:59.809098Z","shell.execute_reply.started":"2024-01-20T02:02:53.008331Z","shell.execute_reply":"2024-01-20T02:02:59.807467Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5596    0.0319    0.0604      1910\n           1     0.6237    0.9846    0.7636      3112\n\n    accuracy                         0.6223      5022\n   macro avg     0.5916    0.5083    0.4120      5022\nweighted avg     0.5993    0.6223    0.4962      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=3,   # Experiment with different values\n    gamma=0.05,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:00:30.798939Z","iopub.execute_input":"2024-01-20T02:00:30.799380Z","iopub.status.idle":"2024-01-20T02:00:39.519313Z","shell.execute_reply.started":"2024-01-20T02:00:30.799347Z","shell.execute_reply":"2024-01-20T02:00:39.518109Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5214    0.1340    0.2132      1910\n           1     0.6350    0.9245    0.7528      3112\n\n    accuracy                         0.6239      5022\n   macro avg     0.5782    0.5293    0.4830      5022\nweighted avg     0.5918    0.6239    0.5476      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=1,   # Experiment with different values\n    gamma=0.1,            # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:20:26.717773Z","iopub.execute_input":"2024-01-20T02:20:26.718174Z","iopub.status.idle":"2024-01-20T02:20:36.092093Z","shell.execute_reply.started":"2024-01-20T02:20:26.718142Z","shell.execute_reply":"2024-01-20T02:20:36.091098Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5491    0.1435    0.2275      1910\n           1     0.6383    0.9277    0.7563      3112\n\n    accuracy                         0.6294      5022\n   macro avg     0.5937    0.5356    0.4919      5022\nweighted avg     0.6044    0.6294    0.5551      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.005,  # Lower learning rate\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=1,   # Experiment with different values\n    gamma=0.15,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:15:21.699093Z","iopub.execute_input":"2024-01-20T02:15:21.699487Z","iopub.status.idle":"2024-01-20T02:15:30.853819Z","shell.execute_reply.started":"2024-01-20T02:15:21.699455Z","shell.execute_reply":"2024-01-20T02:15:30.852969Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.7083    0.0089    0.0176      1910\n           1     0.6212    0.9978    0.7657      3112\n\n    accuracy                         0.6217      5022\n   macro avg     0.6648    0.5033    0.3917      5022\nweighted avg     0.6544    0.6217    0.4812      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=3,   # Experiment with different values\n    gamma=0.05,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:18:04.055398Z","iopub.execute_input":"2024-01-20T02:18:04.055802Z","iopub.status.idle":"2024-01-20T02:18:11.965390Z","shell.execute_reply.started":"2024-01-20T02:18:04.055770Z","shell.execute_reply":"2024-01-20T02:18:11.964086Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5214    0.1340    0.2132      1910\n           1     0.6350    0.9245    0.7528      3112\n\n    accuracy                         0.6239      5022\n   macro avg     0.5782    0.5293    0.4830      5022\nweighted avg     0.5918    0.6239    0.5476      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=600,\n    learning_rate=0.05,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=2,   # Experiment with different values\n    gamma=0.1,            # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:22:12.756952Z","iopub.execute_input":"2024-01-20T02:22:12.757545Z","iopub.status.idle":"2024-01-20T02:22:29.335971Z","shell.execute_reply.started":"2024-01-20T02:22:12.757504Z","shell.execute_reply":"2024-01-20T02:22:29.334866Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5169    0.2084    0.2970      1910\n           1     0.6444    0.8805    0.7442      3112\n\n    accuracy                         0.6249      5022\n   macro avg     0.5806    0.5444    0.5206      5022\nweighted avg     0.5959    0.6249    0.5741      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=300,\n    learning_rate=0.01,\n    max_depth=5,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=0.1,\n    min_child_weight=5,   # Experiment with different values\n    gamma=0.05,           # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:23:21.797408Z","iopub.execute_input":"2024-01-20T02:23:21.798220Z","iopub.status.idle":"2024-01-20T02:23:28.911718Z","shell.execute_reply.started":"2024-01-20T02:23:21.798183Z","shell.execute_reply":"2024-01-20T02:23:28.910787Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5344    0.0366    0.0686      1910\n           1     0.6238    0.9804    0.7625      3112\n\n    accuracy                         0.6215      5022\n   macro avg     0.5791    0.5085    0.4155      5022\nweighted avg     0.5898    0.6215    0.4986      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=4,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:25:47.028325Z","iopub.execute_input":"2024-01-20T02:25:47.028706Z","iopub.status.idle":"2024-01-20T02:25:55.665633Z","shell.execute_reply.started":"2024-01-20T02:25:47.028677Z","shell.execute_reply":"2024-01-20T02:25:55.664676Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5249    0.2644    0.3517      1910\n           1     0.6539    0.8531    0.7404      3112\n\n    accuracy                         0.6292      5022\n   macro avg     0.5894    0.5588    0.5460      5022\nweighted avg     0.6049    0.6292    0.5925      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=6,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:27:39.722162Z","iopub.execute_input":"2024-01-20T02:27:39.722549Z","iopub.status.idle":"2024-01-20T02:27:54.978958Z","shell.execute_reply.started":"2024-01-20T02:27:39.722520Z","shell.execute_reply":"2024-01-20T02:27:54.977793Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5347    0.3188    0.3995      1910\n           1     0.6649    0.8297    0.7382      3112\n\n    accuracy                         0.6354      5022\n   macro avg     0.5998    0.5743    0.5689      5022\nweighted avg     0.6154    0.6354    0.6094      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Updated XGBoost parameters\nmodel = XGBClassifier(\n    n_estimators=800,    # Increased boosting rounds\n    learning_rate=0.05,  # Lower learning rate\n    max_depth=7,         # Increased maximum depth\n    subsample=0.85,      # Experiment with different values\n    colsample_bytree=0.85,  # Experiment with different values\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:33:41.687539Z","iopub.execute_input":"2024-01-20T02:33:41.688029Z","iopub.status.idle":"2024-01-20T02:34:11.178081Z","shell.execute_reply.started":"2024-01-20T02:33:41.687975Z","shell.execute_reply":"2024-01-20T02:34:11.177170Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5310    0.3047    0.3872      1910\n           1     0.6617    0.8348    0.7383      3112\n\n    accuracy                         0.6332      5022\n   macro avg     0.5964    0.5698    0.5628      5022\nweighted avg     0.6120    0.6332    0.6048      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=1000,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=6,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:46:07.688639Z","iopub.execute_input":"2024-01-20T02:46:07.689184Z","iopub.status.idle":"2024-01-20T02:46:36.503222Z","shell.execute_reply.started":"2024-01-20T02:46:07.689132Z","shell.execute_reply":"2024-01-20T02:46:36.502382Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5189    0.3738    0.4346      1910\n           1     0.6720    0.7873    0.7251      3112\n\n    accuracy                         0.6300      5022\n   macro avg     0.5954    0.5805    0.5798      5022\nweighted avg     0.6138    0.6300    0.6146      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=1000,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=5,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,\n    reg_alpha=0.1,\n    reg_lambda=0.1,     # Fraction of features used for fitting each tree   # Experiment with different values    \n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:53:30.001255Z","iopub.execute_input":"2024-01-20T02:53:30.001656Z","iopub.status.idle":"2024-01-20T02:53:51.136796Z","shell.execute_reply.started":"2024-01-20T02:53:30.001620Z","shell.execute_reply":"2024-01-20T02:53:51.135500Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5168    0.3628    0.4263      1910\n           1     0.6694    0.7918    0.7255      3112\n\n    accuracy                         0.6286      5022\n   macro avg     0.5931    0.5773    0.5759      5022\nweighted avg     0.6113    0.6286    0.6117      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,  # Number of boosting rounds (trees)\n    learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n    max_depth=7,        # Maximum depth of each tree\n    subsample=0.8,      # Fraction of samples used for fitting each tree\n    colsample_bytree=0.8,  # Fraction of features used for fitting each tree\n    random_state=42\n)\n\nmodel.fit(Train_X_Tfidf, Train_Y)\ny_pred = model.predict(Test_X_Tfidf)\n\nprint(metrics.classification_report(Test_Y, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T02:56:06.427785Z","iopub.execute_input":"2024-01-20T02:56:06.428199Z","iopub.status.idle":"2024-01-20T02:56:25.011051Z","shell.execute_reply.started":"2024-01-20T02:56:06.428168Z","shell.execute_reply":"2024-01-20T02:56:25.009832Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.5278    0.3335    0.4087      1910\n           1     0.6663    0.8168    0.7339      3112\n\n    accuracy                         0.6330      5022\n   macro avg     0.5970    0.5752    0.5713      5022\nweighted avg     0.6136    0.6330    0.6103      5022\n\n","output_type":"stream"}]}]}