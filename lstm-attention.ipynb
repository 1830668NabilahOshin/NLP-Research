{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1382412,"sourceType":"datasetVersion","datasetId":806606},{"sourceId":7438615,"sourceType":"datasetVersion","datasetId":4329372}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\nfrom tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Convolution1D\nfrom tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\nsize = 200000","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:33:23.380728Z","iopub.execute_input":"2024-01-20T03:33:23.381053Z","iopub.status.idle":"2024-01-20T03:33:23.387742Z","shell.execute_reply.started":"2024-01-20T03:33:23.381027Z","shell.execute_reply":"2024-01-20T03:33:23.386921Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_url = '/kaggle/input/mydataset/train_corr.csv'\ntest_url = '/kaggle/input/mydataset/test_corr.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:33:23.391032Z","iopub.execute_input":"2024-01-20T03:33:23.391319Z","iopub.status.idle":"2024-01-20T03:33:23.667223Z","shell.execute_reply.started":"2024-01-20T03:33:23.391296Z","shell.execute_reply":"2024-01-20T03:33:23.666305Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:33:23.668862Z","iopub.execute_input":"2024-01-20T03:33:23.669271Z","iopub.status.idle":"2024-01-20T03:33:23.673598Z","shell.execute_reply.started":"2024-01-20T03:33:23.669246Z","shell.execute_reply":"2024-01-20T03:33:23.672795Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:33:23.674626Z","iopub.execute_input":"2024-01-20T03:33:23.674928Z","iopub.status.idle":"2024-01-20T03:33:23.791699Z","shell.execute_reply.started":"2024-01-20T03:33:23.674899Z","shell.execute_reply":"2024-01-20T03:33:23.790833Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nMAX_FEATURES = 10000\nEMBED_SIZE = 300\ntokenizer = Tokenizer(num_words=MAX_FEATURES)\ntokenizer.fit_on_texts(df_train['Comment'])\nlist_tokenized_train = tokenizer.texts_to_sequences(df_train['Comment'])\nlist_tokenized_test = tokenizer.texts_to_sequences(df_test['Comment'])\n#RNN_CELL_SIZE = 32\nRNN_CELL_SIZE = 64\nMAX_LEN = 75   # Since our mean length is 56.6\nX_train = pad_sequences(list_tokenized_train, maxlen=MAX_LEN)\nX_test = pad_sequences(list_tokenized_test,maxlen=MAX_LEN)\ny_train = df_train['Error']\ny_test = df_test['Error']","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:37:56.012420Z","iopub.execute_input":"2024-01-20T03:37:56.012760Z","iopub.status.idle":"2024-01-20T03:37:56.878587Z","shell.execute_reply.started":"2024-01-20T03:37:56.012736Z","shell.execute_reply":"2024-01-20T03:37:56.877907Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class Attention(tf.keras.Model):\n    def __init__(self, units):\n        super(Attention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n \n    def call(self, features, hidden):\n        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n        context_vector = attention_weights * features\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n        return context_vector, attention_weights","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:38:05.619845Z","iopub.execute_input":"2024-01-20T03:38:05.620166Z","iopub.status.idle":"2024-01-20T03:38:05.626090Z","shell.execute_reply.started":"2024-01-20T03:38:05.620141Z","shell.execute_reply":"2024-01-20T03:38:05.625379Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"sequence_input = Input(shape=(MAX_LEN,), dtype=\"int32\")\nembedded_sequences = Embedding(MAX_FEATURES, EMBED_SIZE)(sequence_input)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:38:10.753264Z","iopub.execute_input":"2024-01-20T03:38:10.753630Z","iopub.status.idle":"2024-01-20T03:38:10.782871Z","shell.execute_reply.started":"2024-01-20T03:38:10.753599Z","shell.execute_reply":"2024-01-20T03:38:10.782173Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"lstm = Bidirectional(LSTM(RNN_CELL_SIZE, return_sequences = True), name=\"bi_lstm_0\")(embedded_sequences)# Getting our LSTM outputs\n(lstm, forward_h, forward_c, backward_h, backward_c) = Bidirectional(LSTM(RNN_CELL_SIZE, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(lstm)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:38:13.055239Z","iopub.execute_input":"2024-01-20T03:38:13.055720Z","iopub.status.idle":"2024-01-20T03:38:13.857930Z","shell.execute_reply.started":"2024-01-20T03:38:13.055693Z","shell.execute_reply":"2024-01-20T03:38:13.857013Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"state_h = Concatenate()([forward_h, backward_h])\nstate_c = Concatenate()([forward_c, backward_c])\ncontext_vector, attention_weights = Attention(10)(lstm, state_h)\n#dense1 = Dense(20, activation=\"relu\")(context_vector)\ndense1 = Dense(32, activation=\"relu\")(context_vector)\n#dropout = Dropout(0.05)(dense1)\ndropout = Dropout(0.02)(dense1)\noutput = Dense(1, activation=\"sigmoid\")(dropout)\nmodel = keras.Model(inputs=sequence_input, outputs=output)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:38:16.122014Z","iopub.execute_input":"2024-01-20T03:38:16.122313Z","iopub.status.idle":"2024-01-20T03:38:16.221742Z","shell.execute_reply.started":"2024-01-20T03:38:16.122291Z","shell.execute_reply":"2024-01-20T03:38:16.221010Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"METRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:38:58.501443Z","iopub.execute_input":"2024-01-20T03:38:58.502005Z","iopub.status.idle":"2024-01-20T03:38:58.530512Z","shell.execute_reply.started":"2024-01-20T03:38:58.501951Z","shell.execute_reply":"2024-01-20T03:38:58.529786Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nEPOCHS = 20\nhistory = model.fit(X_train,y_train,\n                    batch_size=BATCH_SIZE,\n                    epochs=EPOCHS,\n                    validation_split=0.2)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:59:22.145484Z","iopub.execute_input":"2024-01-20T03:59:22.145818Z","iopub.status.idle":"2024-01-20T04:05:44.119260Z","shell.execute_reply.started":"2024-01-20T03:59:22.145793Z","shell.execute_reply":"2024-01-20T04:05:44.118503Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Epoch 1/20\n126/126 [==============================] - 18s 143ms/step - loss: 0.0495 - tp: 8298.0000 - fp: 164.0000 - tn: 7475.0000 - fn: 129.0000 - accuracy: 0.9818 - precision: 0.9806 - recall: 0.9847 - auc: 0.9976 - val_loss: 2.1261 - val_tp: 2298.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1719.0000 - val_accuracy: 0.5721 - val_precision: 1.0000 - val_recall: 0.5721 - val_auc: 0.0000e+00\nEpoch 2/20\n126/126 [==============================] - 19s 150ms/step - loss: 0.0568 - tp: 8267.0000 - fp: 173.0000 - tn: 7466.0000 - fn: 160.0000 - accuracy: 0.9793 - precision: 0.9795 - recall: 0.9810 - auc: 0.9974 - val_loss: 2.3466 - val_tp: 2222.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1795.0000 - val_accuracy: 0.5531 - val_precision: 1.0000 - val_recall: 0.5531 - val_auc: 0.0000e+00\nEpoch 3/20\n126/126 [==============================] - 18s 139ms/step - loss: 0.0475 - tp: 8284.0000 - fp: 120.0000 - tn: 7519.0000 - fn: 143.0000 - accuracy: 0.9836 - precision: 0.9857 - recall: 0.9830 - auc: 0.9977 - val_loss: 2.1538 - val_tp: 2380.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1637.0000 - val_accuracy: 0.5925 - val_precision: 1.0000 - val_recall: 0.5925 - val_auc: 0.0000e+00\nEpoch 4/20\n126/126 [==============================] - 19s 152ms/step - loss: 0.0412 - tp: 8298.0000 - fp: 109.0000 - tn: 7530.0000 - fn: 129.0000 - accuracy: 0.9852 - precision: 0.9870 - recall: 0.9847 - auc: 0.9982 - val_loss: 2.2576 - val_tp: 2479.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1538.0000 - val_accuracy: 0.6171 - val_precision: 1.0000 - val_recall: 0.6171 - val_auc: 0.0000e+00\nEpoch 5/20\n126/126 [==============================] - 19s 151ms/step - loss: 0.0313 - tp: 8336.0000 - fp: 87.0000 - tn: 7552.0000 - fn: 91.0000 - accuracy: 0.9889 - precision: 0.9897 - recall: 0.9892 - auc: 0.9990 - val_loss: 2.4669 - val_tp: 2321.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1696.0000 - val_accuracy: 0.5778 - val_precision: 1.0000 - val_recall: 0.5778 - val_auc: 0.0000e+00\nEpoch 6/20\n126/126 [==============================] - 19s 151ms/step - loss: 0.0258 - tp: 8339.0000 - fp: 73.0000 - tn: 7566.0000 - fn: 88.0000 - accuracy: 0.9900 - precision: 0.9913 - recall: 0.9896 - auc: 0.9992 - val_loss: 3.0159 - val_tp: 2154.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1863.0000 - val_accuracy: 0.5362 - val_precision: 1.0000 - val_recall: 0.5362 - val_auc: 0.0000e+00\nEpoch 7/20\n126/126 [==============================] - 18s 143ms/step - loss: 0.0251 - tp: 8335.0000 - fp: 63.0000 - tn: 7576.0000 - fn: 92.0000 - accuracy: 0.9904 - precision: 0.9925 - recall: 0.9891 - auc: 0.9992 - val_loss: 2.8173 - val_tp: 2314.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1703.0000 - val_accuracy: 0.5761 - val_precision: 1.0000 - val_recall: 0.5761 - val_auc: 0.0000e+00\nEpoch 8/20\n126/126 [==============================] - 19s 152ms/step - loss: 0.0203 - tp: 8346.0000 - fp: 61.0000 - tn: 7578.0000 - fn: 81.0000 - accuracy: 0.9912 - precision: 0.9927 - recall: 0.9904 - auc: 0.9996 - val_loss: 2.9796 - val_tp: 2324.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1693.0000 - val_accuracy: 0.5785 - val_precision: 1.0000 - val_recall: 0.5785 - val_auc: 0.0000e+00\nEpoch 9/20\n126/126 [==============================] - 18s 143ms/step - loss: 0.0202 - tp: 8351.0000 - fp: 50.0000 - tn: 7589.0000 - fn: 76.0000 - accuracy: 0.9922 - precision: 0.9940 - recall: 0.9910 - auc: 0.9997 - val_loss: 3.1717 - val_tp: 2303.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1714.0000 - val_accuracy: 0.5733 - val_precision: 1.0000 - val_recall: 0.5733 - val_auc: 0.0000e+00\nEpoch 10/20\n126/126 [==============================] - 18s 143ms/step - loss: 0.0177 - tp: 8368.0000 - fp: 46.0000 - tn: 7593.0000 - fn: 59.0000 - accuracy: 0.9935 - precision: 0.9945 - recall: 0.9930 - auc: 0.9995 - val_loss: 3.1309 - val_tp: 2317.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1700.0000 - val_accuracy: 0.5768 - val_precision: 1.0000 - val_recall: 0.5768 - val_auc: 0.0000e+00\nEpoch 11/20\n126/126 [==============================] - 19s 154ms/step - loss: 0.0147 - tp: 8372.0000 - fp: 37.0000 - tn: 7602.0000 - fn: 55.0000 - accuracy: 0.9943 - precision: 0.9956 - recall: 0.9935 - auc: 0.9997 - val_loss: 3.0433 - val_tp: 2391.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1626.0000 - val_accuracy: 0.5952 - val_precision: 1.0000 - val_recall: 0.5952 - val_auc: 0.0000e+00\nEpoch 12/20\n126/126 [==============================] - 19s 151ms/step - loss: 0.0139 - tp: 8376.0000 - fp: 41.0000 - tn: 7598.0000 - fn: 51.0000 - accuracy: 0.9943 - precision: 0.9951 - recall: 0.9939 - auc: 0.9997 - val_loss: 3.5256 - val_tp: 2268.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1749.0000 - val_accuracy: 0.5646 - val_precision: 1.0000 - val_recall: 0.5646 - val_auc: 0.0000e+00\nEpoch 13/20\n126/126 [==============================] - 19s 149ms/step - loss: 0.0136 - tp: 8375.0000 - fp: 36.0000 - tn: 7603.0000 - fn: 52.0000 - accuracy: 0.9945 - precision: 0.9957 - recall: 0.9938 - auc: 0.9998 - val_loss: 3.7372 - val_tp: 2299.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1718.0000 - val_accuracy: 0.5723 - val_precision: 1.0000 - val_recall: 0.5723 - val_auc: 0.0000e+00\nEpoch 14/20\n126/126 [==============================] - 19s 152ms/step - loss: 0.0157 - tp: 8373.0000 - fp: 39.0000 - tn: 7600.0000 - fn: 54.0000 - accuracy: 0.9942 - precision: 0.9954 - recall: 0.9936 - auc: 0.9996 - val_loss: 3.5606 - val_tp: 2321.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1696.0000 - val_accuracy: 0.5778 - val_precision: 1.0000 - val_recall: 0.5778 - val_auc: 0.0000e+00\nEpoch 15/20\n126/126 [==============================] - 19s 151ms/step - loss: 0.0127 - tp: 8377.0000 - fp: 44.0000 - tn: 7595.0000 - fn: 50.0000 - accuracy: 0.9941 - precision: 0.9948 - recall: 0.9941 - auc: 0.9998 - val_loss: 3.3417 - val_tp: 2347.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1670.0000 - val_accuracy: 0.5843 - val_precision: 1.0000 - val_recall: 0.5843 - val_auc: 0.0000e+00\nEpoch 16/20\n126/126 [==============================] - 18s 144ms/step - loss: 0.0171 - tp: 8367.0000 - fp: 43.0000 - tn: 7596.0000 - fn: 60.0000 - accuracy: 0.9936 - precision: 0.9949 - recall: 0.9929 - auc: 0.9995 - val_loss: 3.4421 - val_tp: 2241.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1776.0000 - val_accuracy: 0.5579 - val_precision: 1.0000 - val_recall: 0.5579 - val_auc: 0.0000e+00\nEpoch 17/20\n126/126 [==============================] - 18s 142ms/step - loss: 0.0170 - tp: 8362.0000 - fp: 47.0000 - tn: 7592.0000 - fn: 65.0000 - accuracy: 0.9930 - precision: 0.9944 - recall: 0.9923 - auc: 0.9995 - val_loss: 3.6729 - val_tp: 2152.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1865.0000 - val_accuracy: 0.5357 - val_precision: 1.0000 - val_recall: 0.5357 - val_auc: 0.0000e+00\nEpoch 18/20\n126/126 [==============================] - 18s 142ms/step - loss: 0.0139 - tp: 8376.0000 - fp: 44.0000 - tn: 7595.0000 - fn: 51.0000 - accuracy: 0.9941 - precision: 0.9948 - recall: 0.9939 - auc: 0.9997 - val_loss: 3.1076 - val_tp: 2298.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1719.0000 - val_accuracy: 0.5721 - val_precision: 1.0000 - val_recall: 0.5721 - val_auc: 0.0000e+00\nEpoch 19/20\n126/126 [==============================] - 19s 154ms/step - loss: 0.0116 - tp: 8370.0000 - fp: 30.0000 - tn: 7609.0000 - fn: 57.0000 - accuracy: 0.9946 - precision: 0.9964 - recall: 0.9932 - auc: 0.9999 - val_loss: 3.7998 - val_tp: 2168.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1849.0000 - val_accuracy: 0.5397 - val_precision: 1.0000 - val_recall: 0.5397 - val_auc: 0.0000e+00\nEpoch 20/20\n126/126 [==============================] - 20s 156ms/step - loss: 0.0117 - tp: 8377.0000 - fp: 33.0000 - tn: 7606.0000 - fn: 50.0000 - accuracy: 0.9948 - precision: 0.9961 - recall: 0.9941 - auc: 0.9998 - val_loss: 3.3236 - val_tp: 2370.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1647.0000 - val_accuracy: 0.5900 - val_precision: 1.0000 - val_recall: 0.5900 - val_auc: 0.0000e+00\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = (model.predict(X_test) > 0.5).astype(\"int32\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T04:05:44.121027Z","iopub.execute_input":"2024-01-20T04:05:44.121337Z","iopub.status.idle":"2024-01-20T04:05:46.774778Z","shell.execute_reply.started":"2024-01-20T04:05:44.121309Z","shell.execute_reply":"2024-01-20T04:05:46.773900Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 3s 16ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = (model.predict(X_test) > 0.5).astype(\"int32\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred, target_names = ['Correct','Incorrect']))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T04:05:50.015475Z","iopub.execute_input":"2024-01-20T04:05:50.016006Z","iopub.status.idle":"2024-01-20T04:05:52.756787Z","shell.execute_reply.started":"2024-01-20T04:05:50.015978Z","shell.execute_reply":"2024-01-20T04:05:52.755534Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 3s 17ms/step\n              precision    recall  f1-score   support\n\n     Correct       0.53      0.54      0.53      1910\n   Incorrect       0.71      0.71      0.71      3112\n\n    accuracy                           0.64      5022\n   macro avg       0.62      0.62      0.62      5022\nweighted avg       0.64      0.64      0.64      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred, target_names = ['Correct','Incorrect']))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-20T03:36:43.100174Z","iopub.execute_input":"2024-01-20T03:36:43.101100Z","iopub.status.idle":"2024-01-20T03:36:43.119080Z","shell.execute_reply.started":"2024-01-20T03:36:43.101056Z","shell.execute_reply":"2024-01-20T03:36:43.117955Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Correct       0.53      0.55      0.54      1910\n   Incorrect       0.72      0.70      0.71      3112\n\n    accuracy                           0.65      5022\n   macro avg       0.63      0.63      0.63      5022\nweighted avg       0.65      0.65      0.65      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = (model.predict(X_test) > 0.5).astype(\"int32\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred, target_names = ['Correct','Incorrect']))","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:45:33.015092Z","iopub.execute_input":"2024-01-20T03:45:33.015439Z","iopub.status.idle":"2024-01-20T03:45:39.247309Z","shell.execute_reply.started":"2024-01-20T03:45:33.015412Z","shell.execute_reply":"2024-01-20T03:45:39.246570Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 4s 16ms/step\n              precision    recall  f1-score   support\n\n     Correct       0.53      0.55      0.54      1910\n   Incorrect       0.72      0.70      0.71      3112\n\n    accuracy                           0.65      5022\n   macro avg       0.63      0.63      0.63      5022\nweighted avg       0.65      0.65      0.65      5022\n\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = (model.predict(X_test) > 0.5).astype(\"int32\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred, target_names = ['Correct','Incorrect']))","metadata":{},"execution_count":null,"outputs":[]}]}